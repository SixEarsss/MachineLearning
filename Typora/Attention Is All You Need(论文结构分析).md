# Attention Is All You Need(论文结构分析)

### 1.他们为什么做这项工作：

背景：主流的序列转换模型都是基于复杂的循环神经网络或卷积神经网络，且都包含了一个encoder和一个decoder。

递归模型在使用时，内部的固有顺序阻碍了训练样本的并行化，序列较长时内存限制了样本的批处理，顺序计算的基本约束仍然存在。

目标：减少序列计算。

### 2.别人做过的工作与缺陷：

Extended Neural GPU [16],ByteNet[18],和ConvS2S[9] 

在这些模型中，将来自两个任意输入或输出位置的信号关联起来所需的操作数，随位置间的距离而增长。这使得学习远距离位置之间的依赖性变得更加困难。

### 3.他们大概是怎么做这项工作的：

建立了Transformer模型，完全利用self-attention来计算输入和输出，通过循环attention机制替代序列对齐的循环，更好地进行并行化计算。

### 4.他们的这项工作，做的好不好？好在哪里：

相当好！

（1）突破传统模型的限制：Transformer是第一个完全依赖于self-attention来计算其输入和输出表示而不使用序列对齐的RNN或卷积的转换模型；

（2）提高计算速度：相较于之前的模型Transformer允许并行计算，大大提高了计算效率，训练所需要的时间更少；

（3）更高的模型质量：在自然语言处理任务如机器翻译上，Transformer的表现优于其他模型；

（4）广泛的应用前景：Transfomer还被广泛应用于处理图像、音频和视频等大型输入和输出。

### 5.他们的这项工作，有没有不好之处？不好在哪里：

有

（1）高计算成本：需要超大规模的样本数据，普通规模的数据难以达到预期效果，难以学习到复杂的依赖关系以及参数的最佳值；

（2）高硬件要求：Transformer的并行化处理需要大量的GPU或TPU等高性能硬件进行训练；

（3）训练较复杂：模型较为复杂且超参数的数量巨大，需要仔细地调整超参数才能获得较好的性能；

（4）易发生过拟合：Transformer的模型参数量巨大，一旦训练数据不足，就容易发生过拟合；

（5）模型解释性较差：Transformer的注意力机制使得我们可以通过注意力权重查看模型关注的部分，但模型的整体决策过程仍然是复杂且难以完全解释的，内部大量的复杂运算使得无法体现出内部清晰的逻辑过程，我们无法简单地看出决策背后的逻辑。

（6）推理速度较慢：面对长序列的生成任务，Transformer的推理速度较慢，在翻译等需要快速响应的任务中会对用户体验造成不良影响。

### 6.他们是怎么设计实验证明他们做的好的：

（1）WMT机器翻译任务：在WMT的英语-德语的翻译任务上，Transformer的BLEU评分高于其他模型，并且训练时间较短；

（2）消融实验：在Results中的Model Variations中作者尝试改变attention head的数量、attention key和value的维度等组件，发现模型质量出现显著下降，从而说明这些组件的重要性；

（3）self-attention的选择：作者将self-attention layers与recurrent layers和convolutional layers进行三方面比较，一是每层的总计算复杂度，二是可以并行化的计算量，三是网络中长距离依赖关系之间的路径长度。

通过这些比较实验，作者成功解释了为什么选择self-attention；

（4）英文选区解析实验：该实验使输出受到很强的结构性约束，并且比输入要长很多，Transformer的表现要优于其他模型，此实验用以评估Transformer能否拓展到其他任务。