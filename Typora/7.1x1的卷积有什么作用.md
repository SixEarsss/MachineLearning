#  1*1的卷积有什么作用

### 1.降维与升维：

这里提到的维度改变主要是改变特征图的通道数，而图像维度并没有改变，即改变第三个维度的大小，输出仍然是三维的$H$X$W$X$C$，在卷积神经网络中，“降维”和“升维”指的主要是通道数的变化（即深度（这里的深度指的是特征图的深度，在卷积操作中输入特征图的第三个维度也被称为深度，而网络的深度是指网络的层数）的变化）。

##### 示例：

假设输入特征图的大小为6x6x32，即6x6的空间尺寸和32个通道。使用16个1x1卷积核，每个卷积核的形状是1x1x32。最后会得到一个6x6x16的输出特征图，这里从32个通道减少到16个通道，故成功实现了降维。

##### 降维的意义：

1.通过降低通道数，减少了后续层的计算量和内存需求。

2.保持了输入特征图的空间信息，因为1x1卷积不影响空间维度（即宽度与高度不变）。

##### 升维的意义：

1.增加了特征图的通道数，使得每个像素位置可以包含更多的特征信息。

2.对特征图进行升维，使特征图包含更丰富的特征，使得网络能够学习更多的模式和特征。

### 2.特征重组：

这里我觉得和传统神经网络中的全连接层操作比较像。1×1卷积对输入的每个像素位置进行线性组合，相当于对各个通道的特征进行加权。通过使用多个 1×1卷积核，我们可以生成多个新的输出通道。这样，网络可以从输入特征图中学习到不同的特征组合。例如，某些卷积核可能会专注于提取边缘特征，而其他卷积核可能会提取纹理或颜色特征。这种特征重组使得网络在进行特征学习时能够更加灵活和高效。

### 3.增强非线性表达能力：

在卷积神经网络中，1×1卷积通常与激活函数结合使用。通过对输入通道进行线性组合，然后应用激活函数，模型能够学习到不同通道之间的复杂关系。

##### 1.线性组合：

1×1卷积对每个像素的每个通道进行线性组合。

##### 2.激活函数：

将线性组合的结果通过激活函数引入非线性，使得网络可以学习到更复杂的特征。

### 4.加深网络深度：

在网络结构中加入1×1卷积层，可以增加网络的深度，而不会显著增加参数量和计算量。这有助于提升网络的表达能力，同时保持较低的计算复杂度。